{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e35d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b81095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model: \n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      " one layer\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      " model params\n",
      "Parameter containing:\n",
      "tensor([[ 0.0228, -0.0377, -0.0368,  ...,  0.0319, -0.0371, -0.0986],\n",
      "        [ 0.0268, -0.0160, -0.0256,  ..., -0.0383,  0.0768,  0.0881],\n",
      "        [ 0.0984, -0.0380, -0.0339,  ..., -0.0013,  0.0983, -0.0512],\n",
      "        ...,\n",
      "        [-0.0319,  0.0415,  0.0150,  ...,  0.0111, -0.0173,  0.0439],\n",
      "        [ 0.0309, -0.0969, -0.0821,  ...,  0.0259,  0.0242,  0.0479],\n",
      "        [ 0.0978,  0.0324,  0.0743,  ...,  0.0207,  0.0603,  0.0195]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0439,  0.0880,  0.0180, -0.0276,  0.0654, -0.0768,  0.0279,  0.0382,\n",
      "         0.0128,  0.0607,  0.0987,  0.0278, -0.0274, -0.0179,  0.0533,  0.0336,\n",
      "         0.0702,  0.0880, -0.0536, -0.0666, -0.0165, -0.0243,  0.0260, -0.0502,\n",
      "         0.0111,  0.0485, -0.0504,  0.0971, -0.0297, -0.0791, -0.0230, -0.0059,\n",
      "        -0.0450,  0.0260, -0.0330, -0.0930, -0.0421, -0.0464,  0.0118, -0.0490,\n",
      "        -0.0791,  0.0194,  0.0382,  0.0472,  0.0905,  0.0400,  0.0586,  0.0962,\n",
      "        -0.0195, -0.0527,  0.0296,  0.0408, -0.0007,  0.0195, -0.0296,  0.0301,\n",
      "         0.0417, -0.0582, -0.0269, -0.0046, -0.0067, -0.0479, -0.0973,  0.0199,\n",
      "         0.0113,  0.0342, -0.0599, -0.0272,  0.0081,  0.0445,  0.0087,  0.0076,\n",
      "        -0.0085,  0.0452,  0.0457, -0.0266,  0.0863, -0.0974,  0.0820,  0.0948,\n",
      "        -0.0674, -0.0944,  0.0431,  0.0219,  0.0418,  0.0933, -0.0703,  0.0065,\n",
      "        -0.0116, -0.0879, -0.0174,  0.0615, -0.0729, -0.0838, -0.0302,  0.0810,\n",
      "         0.0247,  0.0806, -0.0281, -0.0120,  0.0219,  0.0187, -0.0481, -0.0023,\n",
      "        -0.0345, -0.0759,  0.0738, -0.0439,  0.0235,  0.0442, -0.0811, -0.0391,\n",
      "         0.0930,  0.0169, -0.0123,  0.0004, -0.0650, -0.0310,  0.0966,  0.0675,\n",
      "         0.0655, -0.0928,  0.0236,  0.0919,  0.0788, -0.0958, -0.0718,  0.0268,\n",
      "         0.0109, -0.0780,  0.0866, -0.0951,  0.0834, -0.0279,  0.0456, -0.0638,\n",
      "        -0.0757, -0.0933, -0.0606, -0.0975, -0.0306, -0.0993,  0.0038,  0.0933,\n",
      "        -0.0366,  0.0787,  0.0092, -0.0378, -0.0485,  0.0052, -0.0602,  0.0530,\n",
      "        -0.0617, -0.0836,  0.0704,  0.0662, -0.0182,  0.0792,  0.0920, -0.0312,\n",
      "         0.0316,  0.0335, -0.0314,  0.0126, -0.0370, -0.0174, -0.0208, -0.0981,\n",
      "        -0.0043, -0.0726, -0.0944, -0.0562, -0.0697, -0.0112, -0.0036, -0.0635,\n",
      "        -0.0440, -0.0945, -0.0939, -0.0557,  0.0498, -0.0551, -0.0937,  0.0666,\n",
      "        -0.0166, -0.0229, -0.0344, -0.0638,  0.0884, -0.0154,  0.0607, -0.0135,\n",
      "        -0.0466,  0.0455,  0.0943,  0.0376, -0.0535, -0.0054, -0.0454, -0.0455],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0024,  0.0695, -0.0630,  ...,  0.0579, -0.0016, -0.0600],\n",
      "        [-0.0682,  0.0244,  0.0464,  ...,  0.0692, -0.0156,  0.0656],\n",
      "        [ 0.0485, -0.0248, -0.0392,  ...,  0.0209, -0.0120,  0.0357],\n",
      "        ...,\n",
      "        [ 0.0121, -0.0653, -0.0019,  ...,  0.0399, -0.0271,  0.0542],\n",
      "        [-0.0017,  0.0538,  0.0092,  ..., -0.0293,  0.0581, -0.0198],\n",
      "        [-0.0523, -0.0151,  0.0071,  ..., -0.0521, -0.0329,  0.0341]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0157, -0.0384, -0.0379,  0.0143,  0.0203,  0.0307,  0.0399,  0.0091,\n",
      "         0.0593,  0.0258], requires_grad=True)\n",
      "\n",
      " layer params\n",
      "Parameter containing:\n",
      "tensor([[-0.0024,  0.0695, -0.0630,  ...,  0.0579, -0.0016, -0.0600],\n",
      "        [-0.0682,  0.0244,  0.0464,  ...,  0.0692, -0.0156,  0.0656],\n",
      "        [ 0.0485, -0.0248, -0.0392,  ...,  0.0209, -0.0120,  0.0357],\n",
      "        ...,\n",
      "        [ 0.0121, -0.0653, -0.0019,  ...,  0.0399, -0.0271,  0.0542],\n",
      "        [-0.0017,  0.0538,  0.0092,  ..., -0.0293,  0.0581, -0.0198],\n",
      "        [-0.0523, -0.0151,  0.0071,  ..., -0.0521, -0.0329,  0.0341]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0157, -0.0384, -0.0379,  0.0143,  0.0203,  0.0307,  0.0399,  0.0091,\n",
      "         0.0593,  0.0258], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        s = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print(\"The model: \")\n",
    "print(tinymodel)\n",
    "\n",
    "print(\"\\n one layer\")\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print(\"\\n model params\")\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print(\"\\n layer params\")\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c988a8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21981/1509688299.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s = self.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 100)\n",
    "y=tinymodel(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076ffa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimkeys for mr. py",
   "language": "python",
   "name": "aimkeysmachine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
